# ==============================
# ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸: preprocess.py (ì§€ì—­ëª… í‘œì¤€í™” ê°•í™”)
# ==============================

import os
import pandas as pd
import numpy as np
import re

# ------------------------------
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# ------------------------------
def load_csv_with_encoding(filepath):
    encodings = ["utf-8-sig", "utf-8", "cp949", "euc-kr", "latin1"]
    for enc in encodings:
        try:
            df = pd.read_csv(filepath, encoding=enc)
            print(f"  âœ“ ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ (encoding={enc})")
            return df, enc
        except:
            continue
    print(f"  âœ— ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨")
    return None, None


# ------------------------------
# 2. ì»¬ëŸ¼ëª… ì •ë¦¬
# ------------------------------
def clean_column_names(df):
    new_columns = {}
    
    for col in df.columns:
        col_lower = col.lower().strip()
        col_clean = col.strip().replace(" ", "_").replace("(", "").replace(")", "").replace("Â·", "_")
        
        # ì§€ì—­ ê´€ë ¨
        region_keywords = ["í–‰ì •êµ¬ì—­", "í–‰ì •", "ì‹œë„", "ì§€ì—­", "ê´‘ì—­ì§€ìì²´", "êµ¬ë¶„", "region", "Ã‡Ã "]
        if any(keyword in col for keyword in region_keywords):
            new_columns[col] = "region"
        # ê¸°íƒ€
        elif "ì—°ë ¹" in col or "age" in col_lower:
            new_columns[col] = "age"
        elif "ë…¸ì¸" in col or "elderly" in col_lower:
            new_columns[col] = "elderly"
        elif "êµìœ¡ì¸ì›" in col or "education" in col_lower:
            new_columns[col] = "education_people"
        elif "ê¸°ì´ˆì§€ìì²´" in col:
            new_columns[col] = "city"
        elif "ê¸°ê´€" in col or "institutions" in col_lower:
            new_columns[col] = "institutions"
        elif "ìœ„ë„" in col or "latitude" in col_lower:
            new_columns[col] = "latitude"
        elif "ê²½ë„" in col or "longitude" in col_lower:
            new_columns[col] = "longitude"
        else:
            new_columns[col] = col_clean.lower()
    
    df = df.rename(columns=new_columns)
    return df


# ------------------------------
# 3. ì§€ì—­ëª… í‘œì¤€í™” (í•µì‹¬ ê°œì„ !)
# ------------------------------
def standardize_region_names(df):
    """
    ì§€ì—­ëª…ì„ í‘œì¤€í™”í•©ë‹ˆë‹¤.
    - ì˜ë¬¸ ì œê±° (ì„œìš¸ Seoul -> ì„œìš¸íŠ¹ë³„ì‹œ)
    - ê´„í˜¸ì™€ ì½”ë“œ ì œê±° (ì„œìš¸íŠ¹ë³„ì‹œ (1100000000) -> ì„œìš¸íŠ¹ë³„ì‹œ)
    - ì•½ì¹­ì„ ì •ì‹ ëª…ì¹­ìœ¼ë¡œ ë³€í™˜ (ì„œìš¸ -> ì„œìš¸íŠ¹ë³„ì‹œ)
    """
    if "region" not in df.columns:
        return df
    
    # ë¬¸ìì—´ë¡œ ë³€í™˜
    df["region"] = df["region"].astype(str).str.strip()
    
    # 1. ê´„í˜¸ì™€ ë‚´ìš© ì œê±°: "ì„œìš¸íŠ¹ë³„ì‹œ  (1100000000)" -> "ì„œìš¸íŠ¹ë³„ì‹œ"
    df["region"] = df["region"].str.replace(r'\s*\([^)]*\)', '', regex=True)
    
    # 2. ì˜ë¬¸ ì œê±°: "ì„œìš¸ Seoul" -> "ì„œìš¸"
    df["region"] = df["region"].str.replace(r'\s+[A-Za-z]+', '', regex=True)
    
    # 3. ê³µë°± ì •ë¦¬
    df["region"] = df["region"].str.strip()
    
    # 4. í‘œì¤€ ëª…ì¹­ ë§¤í•‘
    region_map = {
        "ì„œìš¸": "ì„œìš¸íŠ¹ë³„ì‹œ",
        "ë¶€ì‚°": "ë¶€ì‚°ê´‘ì—­ì‹œ",
        "ëŒ€êµ¬": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
        "ì¸ì²œ": "ì¸ì²œê´‘ì—­ì‹œ",
        "ê´‘ì£¼": "ê´‘ì£¼ê´‘ì—­ì‹œ",
        "ëŒ€ì „": "ëŒ€ì „ê´‘ì—­ì‹œ",
        "ìš¸ì‚°": "ìš¸ì‚°ê´‘ì—­ì‹œ",
        "ì„¸ì¢…": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
        "ê²½ê¸°": "ê²½ê¸°ë„",
        "ê°•ì›": "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
        "ê°•ì›ë„": "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
        "ì¶©ë¶": "ì¶©ì²­ë¶ë„",
        "ì¶©ë‚¨": "ì¶©ì²­ë‚¨ë„",
        "ì „ë¶": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
        "ì „ë¼ë¶ë„": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
        "ì „ë‚¨": "ì „ë¼ë‚¨ë„",
        "ê²½ë¶": "ê²½ìƒë¶ë„",
        "ê²½ë‚¨": "ê²½ìƒë‚¨ë„",
        "ì œì£¼": "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
    }
    
    df["region"] = df["region"].replace(region_map)
    
    # 5. ê¶Œì—­ ë°ì´í„° ì œê±° (í•©ê³„, ìˆ˜ë„ê¶Œ, ë¹„ìˆ˜ë„ê¶Œ ë“±)
    exclude_keywords = ["í•©ê³„", "ì „êµ­", "ìˆ˜ë„ê¶Œ", "ë¹„ìˆ˜ë„ê¶Œ", "ê¶Œì—­", "NaN", "nan"]
    df = df[~df["region"].isin(exclude_keywords)]
    
    return df


# ------------------------------
# 4. ê´‘ì—­ì§€ìì²´ ë°ì´í„° ì§‘ê³„
# ------------------------------
def aggregate_by_region(df):
    """
    ê¸°ì´ˆì§€ìì²´ ë°ì´í„°ë¥¼ ê´‘ì—­ì§€ìì²´ ë‹¨ìœ„ë¡œ ì§‘ê³„í•©ë‹ˆë‹¤.
    (ë””ì§€í„¸ë°°ì›€í„° íŒŒì¼ìš©)
    """
    if "city" in df.columns and "region" in df.columns:
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ í•©ê³„
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if numeric_cols:
            df_agg = df.groupby("region", as_index=False)[numeric_cols].sum()
            return df_agg
    return df


# ------------------------------
# 5. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
# ------------------------------
def handle_missing_values(df):
    for col in df.columns:
        if df[col].dtype in [np.float64, np.int64]:
            df[col] = df[col].fillna(0)
        else:
            df[col] = df[col].fillna("Unknown")
    return df


# ------------------------------
# 6. ì´ìƒì¹˜ ì²˜ë¦¬
# ------------------------------
def handle_outliers(df):
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        col_values = df[col].astype(float)
        mean_val = col_values.mean()
        std_val = col_values.std()
        
        if std_val == 0:
            continue
        
        z_scores = (col_values - mean_val) / std_val
        outlier_mask = np.abs(z_scores) > 3
        
        if outlier_mask.sum() > 0:
            median_val = col_values.median()
            df[col] = col_values.where(~outlier_mask, median_val)
    
    return df


# ------------------------------
# 7. ìˆ«ì ë¬¸ìì—´ì„ ì‹¤ì œ ìˆ«ìë¡œ ë³€í™˜
# ------------------------------
def convert_numeric_strings(df):
    """
    '51,159,889' ê°™ì€ ì‰¼í‘œ í¬í•¨ ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜
    """
    for col in df.columns:
        if df[col].dtype == 'object':  # ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ
            # ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜ ì‹œë„
            try:
                df[col] = df[col].str.replace(',', '').astype(float)
            except:
                pass  # ë³€í™˜ ì‹¤íŒ¨í•˜ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
    return df


# ------------------------------
# 8. ë©”ì¸ ì‹¤í–‰
# ------------------------------
def main():
    data_dir = "/Users/minseung/Desktop/agencrim/data/rawdata"
    output_dir = "/Users/minseung/Desktop/agencrim/data/processed"
    os.makedirs(output_dir, exist_ok=True)

    if not os.path.exists(data_dir):
        print(f"[ì˜¤ë¥˜] ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_dir}")
        return

    files = [f for f in os.listdir(data_dir) if f.endswith(".csv")]
    print(f"\n{'='*60}")
    print(f"[ë°ì´í„° í´ë” í™•ì¸] {len(files)}ê°œ CSV íŒŒì¼ ë°œê²¬")
    print(f"{'='*60}\n")

    if not files:
        print("[ì˜¤ë¥˜] CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_dfs = []
    file_info = []
    
    for filename in files:
        print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: {filename}")
        filepath = os.path.join(data_dir, filename)
        
        df, encoding = load_csv_with_encoding(filepath)
        
        if df is None:
            print(f"  âš ï¸  ê±´ë„ˆëœ€\n")
            continue
        
        print(f"  ì›ë³¸ ì»¬ëŸ¼: {list(df.columns)[:3]}...")
        print(f"  ì›ë³¸ shape: {df.shape}")
        
        # ì „ì²˜ë¦¬
        df = clean_column_names(df)
        
        if "region" not in df.columns:
            print(f"  âœ— 'region' ì»¬ëŸ¼ ì—†ìŒ â†’ ì œì™¸\n")
            continue
        
        print(f"  âœ“ 'region' ì»¬ëŸ¼ ë°œê²¬")
        
        # ìˆ«ì ë³€í™˜
        df = convert_numeric_strings(df)
        
        # ì§€ì—­ëª… í‘œì¤€í™”
        df = standardize_region_names(df)
        
        # ê¸°ì´ˆì§€ìì²´ ë°ì´í„° ì§‘ê³„
        if "city" in df.columns:
            print(f"  â„¹ï¸  ê¸°ì´ˆì§€ìì²´ ë°ì´í„° â†’ ê´‘ì—­ ë‹¨ìœ„ë¡œ ì§‘ê³„")
            df = aggregate_by_region(df)
        
        df = handle_missing_values(df)
        df = handle_outliers(df)
        
        # region ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ìµœì‹  ë°ì´í„° ìœ ì§€)
        if "ì—°ë„" in df.columns:
            df = df.sort_values("ì—°ë„", ascending=False).drop_duplicates("region", keep="first")
        else:
            df = df.drop_duplicates("region", keep="first")
        
        print(f"  í‘œì¤€í™” í›„ ì§€ì—­: {sorted(df['region'].unique())[:5]}...")
        print(f"  âœ“ ì „ì²˜ë¦¬ ì™„ë£Œ (shape: {df.shape})\n")
        
        all_dfs.append(df)
        file_info.append(filename)

    # ë³‘í•©
    print(f"{'='*60}")
    if len(all_dfs) == 0:
        print("[ì˜¤ë¥˜] ì²˜ë¦¬ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    elif len(all_dfs) == 1:
        print(f"[ì •ë³´] íŒŒì¼ 1ê°œë§Œ ì²˜ë¦¬ë¨")
        master_df = all_dfs[0]
    else:
        print(f"[ë³‘í•© ì‹œì‘] {len(all_dfs)}ê°œ íŒŒì¼ ë³‘í•© ì¤‘...")
        master_df = all_dfs[0]
        print(f"  ê¸°ì¤€: {file_info[0]}")
        print(f"    - shape: {master_df.shape}")
        print(f"    - ì§€ì—­ ìˆ˜: {master_df['region'].nunique()}")
        
        for i, other_df in enumerate(all_dfs[1:], 1):
            before_rows = len(master_df)
            master_df = pd.merge(master_df, other_df, on="region", how="outer")
            print(f"  + {file_info[i]}")
            print(f"    - ë³‘í•© ì „: {before_rows}í–‰ â†’ ë³‘í•© í›„: {len(master_df)}í–‰")
        
        print(f"  âœ“ ë³‘í•© ì™„ë£Œ!")

    # ì €ì¥
    print(f"{'='*60}")
    output_path = os.path.join(output_dir, "cleaned_master.csv")
    master_df.to_csv(output_path, index=False, encoding="utf-8-sig")
    
    print(f"\nâœ… [ì €ì¥ ì™„ë£Œ] {output_path}")
    print(f"   ìµœì¢… shape: {master_df.shape}")
    print(f"   ì§€ì—­ ëª©ë¡ ({master_df['region'].nunique()}ê°œ):")
    for region in sorted(master_df['region'].unique()):
        print(f"     - {region}")
    print(f"\n{'='*60}\n")


if __name__ == "__main__":
    main()
